/**
 * (C) Copyright IBM Corp. 2025.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { CompletionsLogProbResult, Usage } from '../tokens';

/**
 * A legacy text completions response choice.
 */
export interface CompletionsChoice {
  /** The reason the model stopped generating tokens. This will be:
   *  - `"stop"` if the model hit a natural stop point or a provided stop sequence
   *  - `"length"` if the maximum number of tokens specified in the request was reached
   *  - `"content_filter"` if content was omitted due to a flag from our content filters.
   */
  finish_reason?: string;
  /** Index of the choice in the response. */
  index?: number;
  /** Log probabilities associated with the generated tokens. */
  logprobs?: CompletionsLogProbResult;
  /** Text generated by the model for the choice. */
  text?: string;
}

/**
 * A legacy text completion response generated by a model.
 */
export interface CompletionsResponse {
  /** Indicates whether the request was cached. */
  cached?: boolean;
  /** A list of completion choices the model generated for the input prompt. */
  choices: CompletionsChoice[];
  /** The UNIX timestamp (in seconds) of when the completion was created. */
  created?: number;
  /** A unique identifier for the completion. */
  id: string;
  /** The ID of the model used for the completion. */
  model: string;
  /** Object type, which is always `"text_completion"`. */
  object: string;
  /** The backend configuration that the model runs with. Can be used in conjunction with the seed request
   *  parameter to understand when backend changes have been made that might impact determinism.
   */
  system_fingerprint?: string;
  /** Usage information for a model request. */
  usage?: Usage;
}
